{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic driving agent\n",
    "The first task involved implementing an agent with completely random behavior, in order to get accustomed to the interface of the simulator, and get a baseline to improve upon.\n",
    "### Performance\n",
    "As expected, randomly choosing an action results in poor performance: the agent doesn't obey traffic rules, nor does it reach its destination in time. (At least most of the time.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a set of states\n",
    "In order to create an agent which can behave in a more intelligent manner, a set of states must be identified. Ideally, these states should contain all of the necessary information about the world that is needed for choosing the correct action.\n",
    "I took a simple approach, and defined the states as unique permutations of the necessary input values, in the following order:\n",
    "1. The state of the traffic light (either 'green' or 'red')\n",
    "2. The direction the car in the oncoming lane is headed\\*\n",
    "3. The direction the car in the lane to the right is headed\\*\n",
    "4. The direction the car in the lane to the left is headed\\*\n",
    "5. The direction recommended by the route planner\n",
    "\n",
    "\\* (if there is no car there, the value is None)\n",
    "\n",
    "So, for example, one of the states my agent can experience is ('green', None, None, None, 'left'). This results in a few superfluous states (e.g. because if the traffic light signals red, the car on the oncoming lane will always stop; the state ('red', 'forward', None, None, 'left') will never be visited in practice).\n",
    "\n",
    "On the flipside, it's easy to see why this approach will work:\n",
    "* These inputs are the same as the \"inputs\" considered by actual human drivers on a high level\n",
    "* The states encode all of the available information (except the time left until the deadline is reached), so if this state space wasn't big enough, then the project would be impossible without extending the simulator to provide the cab with more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Q-Learning\n",
    "After implementing a simple version of Q-Learning (and an action selection method that gradually becomes less explorative as the number of iterations approaches 100), the behavior of the cab greatly improved:\n",
    "* It started to obey the traffic lights\n",
    "* Followed the directions provided by the route planner\n",
    "\n",
    "However, occassionally it still made mistakes when encountering other cars, even after 100 iterations.\n",
    "## Non-naive exploration\n",
    "The agent takes the learned Q-values into account even when it takes an explorative action. This is done by using the softmax function to transform the Q-values into probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing the driving agent\n",
    "My belief was that the nonoptimal behavior when encountering other cars was the result of the relative rarity of the event: because there were only 3 other cars in the simulation, the agent didn't encounter them often enough. After I added 7 more cars to the simulation, the results confirmed my intuition.\n",
    "\n",
    "I think this problem could have also been solved by using a more intelligently designed state space, but in my opinion that would have defeated the whole purpose of learning a policy.\n",
    "\n",
    "## Final performance\n",
    "The learned policy after 100 iterations seems to be very close to the optimal policy (I haven't observed any attempted illegal moves, and the cab seems to always follow the directions of the planner).\n",
    "\n",
    "I think the time it takes to arrive at the destination could be further reduced by replacing the route planner. A better system could take into account that the world \"wraps around\", and perhaps the timing of the traffic lights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
